{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foodvocate: Asynchronous Independent Cascade Model (AsIC)\n",
    "Author: [Meng-Chieh Liu](https://github.com/MengChiehLiu)  \n",
    "Date: 2023/6/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Instagram.data.datasets import datasets, bloggers, frequency_count\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "n = 578 # number of unique nodes\n",
    "d = 91 # number of datasets\n",
    "max_timeDecay = 30 # maximum time decay days\n",
    "beta_theta = np.zeros(n*4) # initialize value\n",
    "connected_node = 24 # average node in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted g: the possibility of not in an document\n",
    "frequency = np.array(list(frequency_count.values()))\n",
    "show = frequency/d\n",
    "no_show = 1 - show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloggers_index = {v:k for k,v in bloggers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_dataset = []\n",
    "    first_time_stamp = dataset[0][1]\n",
    "    for user_name, time_stamp in dataset:\n",
    "        new_dataset.append((bloggers_index[user_name], (time_stamp-first_time_stamp)/86400))\n",
    "    new_datasets.append(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "T = []\n",
    "W = []\n",
    "\n",
    "for new_dataset in new_datasets:\n",
    "    Activated = []\n",
    "    TimeDacays = []\n",
    "    w = []\n",
    "\n",
    "    for i in range(1, len(new_dataset)): # node be triggered (after)\n",
    "        node2, time2 = new_dataset[i]\n",
    "        activated = np.array([])\n",
    "        timeDacays = np.array([])\n",
    "\n",
    "        for j in range(i): # node trigger (before)\n",
    "            node1, time1 = new_dataset[j]\n",
    "            if time2-time1 <= max_timeDecay:\n",
    "                x = np.zeros(n*2)\n",
    "                x[node1] = 1\n",
    "                x[n+node2] = 1\n",
    "                activated = np.concatenate([activated, x])\n",
    "                timeDacays = np.append(timeDacays, time2-time1)\n",
    "\n",
    "        if timeDacays.size > 0:\n",
    "            w.append(node2)\n",
    "            Activated.append(activated.reshape(-1, n*2))\n",
    "            TimeDacays.append(timeDacays)\n",
    "    \n",
    "    A.append(Activated)\n",
    "    T.append(TimeDacays)\n",
    "    W.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal = np.eye(n)\n",
    "g_matrixs = []\n",
    "for i in range(n):\n",
    "    g_matrix = np.zeros((n,n))\n",
    "    g_matrix[:, i] = 1\n",
    "    g_matrix = np.concatenate((g_matrix, diagonal), axis=1)\n",
    "    g_matrixs.append(g_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beta's grad ###\n",
    "# beta here is np.dot(X, beta)\n",
    "# p = sigmoid(beta)\n",
    "# r = np.exp(theta)\n",
    "# prob = p*r*np.exp(-r*time_dacays)\n",
    "# neg_prob = p*np.exp(-r*time_dacays) + (1-p)\n",
    "\n",
    "# d(prob) / d(p) = r * np.exp(-r * time_dacays)  \n",
    "# d(neg_prob) / d(p) = np.exp(-r * time_dacays) - 1\n",
    "# d(p) / d(beta) = p * (1-p)\n",
    "# d(prob) / d(beta) = r * np.exp(-r * time_dacays) * p * (1-p)\n",
    "#                   = prob * (1-p)\n",
    "# d(neg_prob) / d(beta) = (np.exp(-r * time_dacays) - 1) * p * (1-p)\n",
    "\n",
    "\n",
    "### theta's grad ###\n",
    "# theta here is np.dot(X, theta)\n",
    "# p = sigmoid(beta)\n",
    "# r = np.exp(theta)\n",
    "# prob = p*r*np.exp(-r*time_dacays)\n",
    "# neg_prob = p*np.exp(-r*time_dacays) + (1-p)\n",
    "\n",
    "# d(prob) / d(r) = (d(p*r)/d(r) * np.exp(-r*time_dacays)) + (d(np.exp(-r*time_dacays))/d(r)* (p*r))\n",
    "#                = p*np.exp(-r*time_dacays) + -time_dacays*np.exp(-r*time_dacays)*(p*r)\n",
    "#                = (p - p*r*time_dacays) * np.exp(-r*time_dacays)\n",
    "#                = p * (1 - r * time_dacays) * np.exp(-r * time_dacays)\n",
    "# d(neg_prob) / d(r) = d(neg_prob)/d(np.exp(-r*time_dacays)) * d(np.exp(-r*time_dacays))/d(r)\n",
    "#                    = p * (-time_dacays * np.exp(-r * time_dacays))\n",
    "#                    = -p * time_dacays * np.exp(-r * time_dacays)\n",
    "# d(r) / d(theta) = r\n",
    "# d(prob) / d(theta) = p * (1 - r * time_dacays) * np.exp(-r * time_dacays) * r\n",
    "#                    = prob * (1 - r * time_dacays)\n",
    "# d(neg_prob) / d(theta) = -p * time_dacays * np.exp(-r * time_dacays) * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    p = x.copy()\n",
    "    p[x >= 0] = 1.0 / (1 + np.exp(-x[x >= 0]))\n",
    "    p[x < 0] = np.exp(x[x < 0]) / (1 + np.exp(x[x < 0])) # alternative method\n",
    "    return p\n",
    "\n",
    "def cal_prob(p, r, time_dacays, idx):\n",
    "    prob = p*r*np.exp(-r*time_dacays) * show[idx]\n",
    "    beta_grad = prob * (1-p) * show[idx]\n",
    "    theta_grad = prob * (1 - r * time_dacays) * show[idx]\n",
    "    return prob, beta_grad, theta_grad\n",
    "\n",
    "def cal_neg_prob(p, r, time_dacays, idx):\n",
    "    neg_prob = (p*np.exp(-r*time_dacays)+ (1-p)) * show[idx]\n",
    "    neg_beta_grad = (np.exp(-r * time_dacays) - 1) * p * (1-p) * show[idx]\n",
    "    neg_theta_grad = -p * time_dacays * np.exp(-r * time_dacays) * r * show[idx]\n",
    "    return neg_prob, neg_beta_grad, neg_theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### h' grad\n",
    "# beta here is np.dot(X, beta)\n",
    "# a = np.log(neg_probs).sum(), b = np.log(const)\n",
    "# const = (probs/neg_probs).sum()\n",
    "\n",
    "# d(a) / d(beta) = d(a)/d(neg_probs) * d(neg_probs)/d(beta)\n",
    "#                = ((1/neg_probs) * neg_beta_grad).sum()\n",
    "# d(b) / d(beta) = d(b) / d(const) * d(const) / d(beta)\n",
    "#                = 1/const * (d(probs)/d(beta) * neg_probs - probs * d(neg_probs)/d(beta)) / neg_probs*neg_probs\n",
    "#                = 1/const * (beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs\n",
    "# d(h) / d(beta) = d(a)/d(beta) + d(b)/d(beta) \n",
    "#                = ((1/neg_probs) * neg_beta_grad).sum() + 1/const * (beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs\n",
    "\n",
    "# thete is the same as beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_h_grad(x, const, probs, neg_probs, beta_grad, neg_beta_grad, theta_grad, neg_theta_grad):\n",
    "    beta_grad = (1/neg_probs)*neg_beta_grad + 1/const * (beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs\n",
    "    theta_gard = (1/neg_probs)*neg_theta_grad + 1/const * (theta_grad*neg_probs - probs*neg_theta_grad)/neg_probs*neg_probs\n",
    "    return np.concatenate((np.dot(beta_grad, x), np.dot(theta_gard, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### g' grad\n",
    "# beta here is np.dot(X, beta)\n",
    "# p = sigmoid(beta)\n",
    "# g_probs = show*(1-p) + no_show\n",
    "# g = log(g_probs)*c\n",
    "\n",
    "# d(g_probs)/d(beta) = d(g_probs)/d(p) * d(p)/d(beta)\n",
    "#                    = -show * p*(1-p)\n",
    "# d(g) / d(beta) = d(g)/d(g_probs) * d(g_probs)/d(beta)\n",
    "#                = c/g_probs * (-show*p*(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g: Given that node1 existed, the probability that node1 did not trigger node2 can be divided to:\n",
    "# 1. node2 show up : show[node2] * (1-p)\n",
    "# 2. node2 not show up : no_show[node2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(beta_theta):\n",
    "    beta = beta_theta[:n*2]\n",
    "    theta = beta_theta[n*2:]\n",
    "\n",
    "    log_likelihood = 0\n",
    "    gradients = np.zeros_like(beta_theta)  # initialize gradients\n",
    "\n",
    "    for Activated, TimeDacays, w in zip(A, T, W):\n",
    "\n",
    "        for x, dacays, idx in zip(Activated, TimeDacays, w):\n",
    "            p = sigmoid(np.dot(x, beta))\n",
    "            r = np.exp(np.dot(x, theta))\n",
    "            \n",
    "            probs, beta_grad, theta_grad = cal_prob(p, r, dacays, idx) # X\n",
    "            neg_probs, neg_beta_grad, neg_theta_grad = cal_neg_prob(p, r, dacays, idx) # Y\n",
    "            \n",
    "            # calculate h\n",
    "            const = (probs/neg_probs).sum()\n",
    "            h = (np.log(neg_probs).sum() + np.log(const))\n",
    "            h_grad = cal_h_grad(x, const, probs, neg_probs, beta_grad, neg_beta_grad, theta_grad, neg_theta_grad)\n",
    "\n",
    "            # update\n",
    "            log_likelihood -= h\n",
    "            gradients -= h_grad\n",
    "    \n",
    "    # calculate g\n",
    "    for i in range(n):\n",
    "        c = np.ones(n)\n",
    "        c[i] = 0\n",
    "        p = sigmoid(np.dot(g_matrixs[i], beta))\n",
    "        g_probs = show*(1-p) + no_show\n",
    "        g = (np.log(g_probs)*c).sum() * frequency_count[i] * (n-connected_node)/n\n",
    "        g_grad = c/g_probs * (-show*p*(1-p)) * frequency_count[i] * (n-connected_node)/n\n",
    "        g_grad = np.dot(g_grad, g_matrixs[i])\n",
    "        log_likelihood -= g\n",
    "        gradients[:n*2] -= g_grad\n",
    "\n",
    "    print(f'\\rlog_likelihood: {log_likelihood}', end='')\n",
    "    return log_likelihood, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood: 29530.735887694656"
     ]
    }
   ],
   "source": [
    "maxmize_log_likelihood = minimize(negative_log_likelihood, x0=beta_theta, method='BFGS',\n",
    "                                  jac=True, options={'gtol':1e-3, 'maxiter':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_beta_theta = maxmize_log_likelihood.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_beta = optimized_beta_theta[:n*2]\n",
    "optimized_theta = optimized_beta_theta[n*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_matrix = np.array([])\n",
    "\n",
    "for i, g_matrix in enumerate(g_matrixs):\n",
    "    \n",
    "    prob_row = sigmoid(np.dot(g_matrix, optimized_beta)) * show\n",
    "    probability_matrix = np.concatenate((probability_matrix, prob_row))\n",
    "\n",
    "probability_matrix = probability_matrix.reshape(-1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(probability_matrix)\n",
    "for i in range(n):\n",
    "    df[i][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.000000\n",
       "3      0.001296\n",
       "53     0.001514\n",
       "362    0.001774\n",
       "287    0.001802\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107    0.004955\n",
       "238    0.004962\n",
       "33     0.004979\n",
       "61     0.005102\n",
       "24     0.005150\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/probability_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
