{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Instagram.data.datasets import datasets, bloggers\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, approx_fprime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "n = 578 # nodes\n",
    "max_timeDecay = 30 # days\n",
    "beta_theta = np.zeros(n*4) # initialize value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloggers_index = {v:k for k,v in bloggers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_dataset = []\n",
    "    first_time_stamp = dataset[0][1]\n",
    "    for user_name, time_stamp in dataset:\n",
    "        new_dataset.append((bloggers_index[user_name], (time_stamp-first_time_stamp)/86400))\n",
    "    new_datasets.append(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "T = []\n",
    "C = []\n",
    "W = []\n",
    "for new_dataset in new_datasets:\n",
    "    Activated = []\n",
    "    TimeDacays = []\n",
    "    c = np.ones(n)\n",
    "    w = []\n",
    "\n",
    "    for i in range(1, len(new_dataset)): # node be triggered (after)\n",
    "        node2, time2 = new_dataset[i]\n",
    "        c[node2] = 0\n",
    "        activated = np.array([])\n",
    "        timeDacays = np.array([])\n",
    "\n",
    "        for j in range(i): # node trigger (before)\n",
    "            node1, time1 = new_dataset[j]\n",
    "            if time2-time1 <= max_timeDecay:\n",
    "                x = np.zeros(n*2)\n",
    "                x[node1] = 1\n",
    "                x[n+node2] = 1\n",
    "                activated = np.concatenate([activated, x])\n",
    "                timeDacays = np.append(timeDacays, time2-time1)\n",
    "\n",
    "        if timeDacays.size > 0:\n",
    "            w.append(node2)\n",
    "            Activated.append(activated.reshape(-1, n*2))\n",
    "            TimeDacays.append(timeDacays)\n",
    "    \n",
    "    A.append(Activated)\n",
    "    T.append(TimeDacays)\n",
    "    C.append(c)\n",
    "    W.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal = np.eye(n)\n",
    "g_matrixs = []\n",
    "for i in range(n):\n",
    "    g_matrix = np.zeros((n,n))\n",
    "    g_matrix[:, i] = 1\n",
    "    g_matrix = np.concatenate((g_matrix, diagonal), axis=1)\n",
    "    g_matrixs.append(g_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beta's grad ###\n",
    "# beta here is np.dot(X, beta)\n",
    "# p = sigmoid(beta)\n",
    "# r = np.exp(theta)\n",
    "# prob = p*r*np.exp(-r*time_dacays)\n",
    "# neg_prob = p*np.exp(-r*time_dacays) + (1-p)\n",
    "\n",
    "# d(prob) / d(p) = r * np.exp(-r * time_dacays)  \n",
    "# d(neg_prob) / d(p) = np.exp(-r * time_dacays) - 1\n",
    "# d(p) / d(beta) = p * (1-p)\n",
    "# d(prob) / d(beta) = r * np.exp(-r * time_dacays) * p * (1-p)\n",
    "#                   = prob * (1-p)\n",
    "# d(neg_prob) / d(beta) = (np.exp(-r * time_dacays) - 1) * p * (1-p)\n",
    "\n",
    "\n",
    "### theta's grad ###\n",
    "# theta here is np.dot(X, theta)\n",
    "# p = sigmoid(beta)\n",
    "# r = np.exp(theta)\n",
    "# prob = p*r*np.exp(-r*time_dacays)\n",
    "# neg_prob = p*np.exp(-r*time_dacays) + (1-p)\n",
    "\n",
    "# d(prob) / d(r) = (d(p*r)/d(r) * np.exp(-r*time_dacays)) + (d(np.exp(-r*time_dacays))/d(r)* (p*r))\n",
    "#                = p*np.exp(-r*time_dacays) + -time_dacays*np.exp(-r*time_dacays)*(p*r)\n",
    "#                = (p - p*r*time_dacays) * np.exp(-r*time_dacays)\n",
    "#                = p * (1 - r * time_dacays) * np.exp(-r * time_dacays)\n",
    "# d(neg_prob) / d(r) = d(neg_prob)/d(np.exp(-r*time_dacays)) * d(np.exp(-r*time_dacays))/d(r)\n",
    "#                    = p * (-time_dacays * np.exp(-r * time_dacays))\n",
    "#                    = -p * time_dacays * np.exp(-r * time_dacays\n",
    "# d(r) / d(theta) = r\n",
    "# d(prob) / d(theta) = p * (1 - r * time_dacays) * np.exp(-r * time_dacays) * r\n",
    "#                    = prob * (1 - r * time_dacays)\n",
    "# d(neg_prob) / d(theta) = -p * time_dacays * np.exp(-r * time_dacays) * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def cal_prob(p, r, time_dacays):\n",
    "    prob = p*r*np.exp(-r*time_dacays)\n",
    "    beta_grad = prob * (1-p)\n",
    "    theta_grad = prob * (1 - r * time_dacays)\n",
    "    return prob, beta_grad, theta_grad\n",
    "\n",
    "def cal_neg_prob(p, r, time_dacays):\n",
    "    neg_prob = p*np.exp(-r*time_dacays)+(1-p)\n",
    "    neg_beta_grad = (np.exp(-r * time_dacays) - 1) * p * (1-p)\n",
    "    neg_theta_grad = -p * time_dacays * np.exp(-r * time_dacays) * r\n",
    "    return neg_prob, neg_beta_grad, neg_theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "### h' grad\n",
    "# beta here is np.dot(X, beta)\n",
    "# a = np.log(neg_probs), b = np.log(const)\n",
    "\n",
    "\n",
    "# d(a) / d(beta) = d(a)/d(neg_probs) * d(neg_probs)/d(beta)\n",
    "#                = (1/neg_probs) * neg_beta_grad\n",
    "# d(b) / d(beta) = (d(probs)/d(beta) * neg_probs - probs * d(neg_probs)/d(beta)) / neg_probs*neg_probs\n",
    "#                = (beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs\n",
    "# d(h) / d(beta) = d(a)/d(beta) + d(b)/d(beta) \n",
    "#                = (1/neg_probs)*neg_beta_grad + ((beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs).sum()\n",
    "\n",
    "# thete is the same as beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_h_grad(x, probs, neg_probs, beta_grad, neg_beta_grad, theta_grad, neg_theta_grad):\n",
    "    beta_grad = (1/neg_probs)*neg_beta_grad +((beta_grad*neg_probs - probs*neg_beta_grad)/neg_probs*neg_probs).sum()\n",
    "    theta_gard = (1/neg_probs)*neg_theta_grad +((theta_grad*neg_probs - probs*neg_theta_grad)/neg_probs*neg_probs).sum()\n",
    "    return np.concatenate((np.dot(beta_grad, x), np.dot(theta_gard, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### g' grad\n",
    "# beta here is np.dot(X, beta)\n",
    "# p = sigmoid(beta)\n",
    "# g_probs = 1-p\n",
    "# g = log(g_probs)*c\n",
    "\n",
    "# d(g_probs)/d(beta) = -p * (1-p)\n",
    "# d(g) / d(beta) = d(g)/d(g_probs) * d(g_probs)/d(beta)\n",
    "#                = c/(1-p) * -p * (1-p)\n",
    "#                = -c*p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_g_prob(X, beta, c):\n",
    "    p = sigmoid(np.dot(X, beta))\n",
    "    return 1-p, -p*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(beta_theta):\n",
    "    beta = beta_theta[:n*2]\n",
    "    theta = beta_theta[n*2:]\n",
    "\n",
    "    log_likelihood = 0\n",
    "    gradients = np.zeros_like(beta_theta)  # initialize gradients\n",
    "\n",
    "    for Activated, TimeDacays, c, w in zip(A, T, C, W):\n",
    "\n",
    "        for x, dacays, idx in zip(Activated, TimeDacays, w):\n",
    "            p = sigmoid(np.dot(x, beta))\n",
    "            r = np.exp(np.dot(x, theta))\n",
    "            \n",
    "            probs, beta_grad, theta_grad = cal_prob(p, r, dacays) # X\n",
    "            neg_probs, neg_beta_grad, neg_theta_grad = cal_neg_prob(p, r, dacays) # Y\n",
    "            \n",
    "            # calculate h\n",
    "            const = (probs/neg_probs).sum()\n",
    "            h = np.ma.log(neg_probs*const).filled(-23).sum() # log(1e-10) ~ -23\n",
    "            h_grad = cal_h_grad(x, probs, neg_probs, beta_grad, neg_beta_grad, theta_grad, neg_theta_grad)\n",
    "\n",
    "            # calculate g\n",
    "            g_probs, g_grad = cal_g_prob(g_matrixs[idx], beta, c)\n",
    "            g = (np.log(g_probs)*c).sum()\n",
    "            g_grad = np.dot(g_grad, g_matrixs[idx])\n",
    "\n",
    "            # update\n",
    "            log_likelihood -= h+g\n",
    "            gradients -= h_grad\n",
    "            gradients[:2*n] -= g_grad\n",
    "\n",
    "    return log_likelihood, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 53785.152588\n",
      "         Iterations: 65\n",
      "         Function evaluations: 126\n",
      "         Gradient evaluations: 115\n"
     ]
    }
   ],
   "source": [
    "maxmize_log_likelihood = minimize(negative_log_likelihood, x0=beta_theta, method='BFGS',\n",
    "                                  jac=True, options={'gtol':1e-6, 'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('beta_theta.pkl', 'wb') as f:\n",
    "    pickle.dump(maxmize_log_likelihood.x, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('beta_theta.pkl', 'rb') as f:\n",
    "    optimized_beta_theta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_beta = optimized_beta_theta[:2*n]\n",
    "optimized_theta = optimized_beta_theta[2*n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_matrix = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g_matrix in g_matrixs:\n",
    "    \n",
    "    prob_row = sigmoid(np.dot(g_matrix, optimized_beta))\n",
    "    probability_matrix = np.concatenate((probability_matrix, prob_row))\n",
    "\n",
    "probability_matrix = probability_matrix.reshape(-1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(probability_matrix)\n",
    "for i in range(n):\n",
    "    df[i][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('probability_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
